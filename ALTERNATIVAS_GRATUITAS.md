# Alternativas Gratuitas a OpenAI

## üéØ Opci√≥n Recomendada: Ollama (Local)

### Instalaci√≥n de Ollama

1. **Instalar Ollama:**
   ```bash
   # En Linux/macOS
   curl -fsSL https://ollama.ai/install.sh | sh
   
   # En Windows
   # Descargar desde https://ollama.ai/download
   ```

2. **Descargar un modelo:**
   ```bash
   # Modelo recomendado (equilibrio entre velocidad y calidad)
   ollama pull llama3.2
   
   # Alternativas:
   ollama pull mistral    # M√°s r√°pido, buena calidad
   ollama pull codellama  # Especializado en c√≥digo
   ollama pull phi3       # Muy r√°pido, buena para tareas simples
   ```

3. **Iniciar Ollama:**
   ```bash
   ollama serve
   ```

4. **Instalar la dependencia en tu proyecto:**
   ```bash
   npm install ollama
   ```

### Ventajas de Ollama:
- ‚úÖ **Completamente gratuito**
- ‚úÖ **Funciona offline**
- ‚úÖ **Sin l√≠mites de uso**
- ‚úÖ **Privacidad total** (datos no salen de tu m√°quina)
- ‚úÖ **M√∫ltiples modelos disponibles**

---

## üåê Otras Alternativas Gratuitas

### 1. **Hugging Face Inference API**
```bash
npm install @huggingface/inference
```

**Configuraci√≥n:**
```javascript
import { HfInference } from '@huggingface/inference';

const hf = new HfInference(process.env.HUGGINGFACE_API_KEY);

async function chatWithHuggingFace(prompt) {
  const response = await hf.textGeneration({
    model: 'microsoft/DialoGPT-medium',
    inputs: prompt,
    parameters: {
      max_new_tokens: 300,
      temperature: 0.7
    }
  });
  return response.generated_text;
}
```

**Ventajas:**
- ‚úÖ Gratuito hasta 30,000 requests/mes
- ‚úÖ Muchos modelos disponibles
- ‚úÖ API simple

---

### 2. **Ollama WebUI (Interfaz Web)**
```bash
# Instalar Ollama WebUI
git clone https://github.com/ollama-webui/ollama-webui.git
cd ollama-webui
npm install
npm run dev
```

**Ventajas:**
- ‚úÖ Interfaz web para Ollama
- ‚úÖ Chat visual
- ‚úÖ Gesti√≥n de modelos
- ‚úÖ Completamente gratuito

---

### 3. **LM Studio (Interfaz Gr√°fica)**
- Descargar desde: https://lmstudio.ai/
- Interfaz gr√°fica para modelos locales
- Soporte para m√∫ltiples formatos de modelo

---

### 4. **API de Google Gemini (Gratuito)**
```bash
npm install @google/generative-ai
```

**Configuraci√≥n:**
```javascript
import { GoogleGenerativeAI } from '@google/generative-ai';

const genAI = new GoogleGenerativeAI(process.env.GOOGLE_API_KEY);

async function chatWithGemini(prompt) {
  const model = genAI.getGenerativeModel({ model: "gemini-pro" });
  const result = await model.generateContent(prompt);
  return result.response.text();
}
```

**Ventajas:**
- ‚úÖ 60 requests/minuto gratis
- ‚úÖ Buena calidad
- ‚úÖ API estable

---

### 5. **Claude API (Anthropic)**
```bash
npm install @anthropic-ai/sdk
```

**Configuraci√≥n:**
```javascript
import Anthropic from '@anthropic-ai/sdk';

const anthropic = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY,
});

async function chatWithClaude(prompt) {
  const message = await anthropic.messages.create({
    model: 'claude-3-haiku-20240307',
    max_tokens: 300,
    messages: [{ role: 'user', content: prompt }],
  });
  return message.content[0].text;
}
```

**Ventajas:**
- ‚úÖ 5 requests/minuto gratis
- ‚úÖ Excelente calidad
- ‚úÖ API robusta

---

## üîß Configuraci√≥n en tu Aplicaci√≥n

### Variables de Entorno (.env)
```env
# Ollama (recomendado - gratuito)
OLLAMA_BASE_URL=http://localhost:11434

# Alternativas (opcionales)
HUGGINGFACE_API_KEY=tu_api_key_aqui
GOOGLE_API_KEY=tu_api_key_aqui
ANTHROPIC_API_KEY=tu_api_key_aqui

# OpenAI (respaldo)
OPENAI_API_KEY=tu_api_key_aqui
```

### Instalaci√≥n de Dependencias
```bash
# Para Ollama (recomendado)
npm install ollama

# Para otras alternativas
npm install @huggingface/inference
npm install @google/generative-ai
npm install @anthropic-ai/sdk
```

---

## üìä Comparaci√≥n de Alternativas

| Servicio | Costo | Calidad | Velocidad | Privacidad | Facilidad |
|----------|-------|---------|-----------|------------|-----------|
| **Ollama** | Gratuito | Buena | R√°pida | Total | Media |
| Hugging Face | Gratuito* | Variable | Media | Parcial | F√°cil |
| Google Gemini | Gratuito* | Excelente | R√°pida | Parcial | F√°cil |
| Claude | Gratuito* | Excelente | R√°pida | Parcial | F√°cil |
| OpenAI | Pago | Excelente | R√°pida | Parcial | F√°cil |

*Con l√≠mites mensuales

---

## üöÄ Recomendaci√≥n Final

**Para tu caso, recomiendo Ollama** porque:

1. **Es completamente gratuito** - sin l√≠mites ni costos ocultos
2. **Funciona offline** - no necesitas internet
3. **Privacidad total** - tus datos nunca salen de tu m√°quina
4. **F√°cil de configurar** - ya est√° integrado en tu c√≥digo
5. **Escalable** - puedes cambiar modelos seg√∫n tus necesidades

### Pr√≥ximos Pasos:
1. Instala Ollama: `curl -fsSL https://ollama.ai/install.sh | sh`
2. Descarga un modelo: `ollama pull llama3.2`
3. Inicia Ollama: `ollama serve`
4. Ejecuta tu aplicaci√≥n: `npm run dev:full`

¬°Y listo! Tu aplicaci√≥n funcionar√° completamente gratis con IA local. 